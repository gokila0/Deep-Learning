import pandas as pd

df = pd.read_csv('/content/data (1).csv')
print(df.columns.tolist())

['Socioeconomic Score', 'Study Hours', 'Sleep Hours', 'Attendance (%)', 'Grades']

df.head()
   Socioeconomic_Score	Study_Hours	Sleep_Hours	Attendance (%)	Grades
0	   0.95822	                3.4	        8.2	        53.0	     47.0
1	   0.85566	                3.2	        5.9	        55.0	     35.0
2	   0.68025	                3.2	        9.3	        41.0	     32.0
3	   0.25936	                3.2	        8.2	        47.0	     34.0
4	   0.60447	                3.8	       10.0	        75.0	     33.0


!pip install -q keras-tuner

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow import keras
from keras.models import Sequential
from keras.layers import Dense
import keras_tuner as kt

# Load Dataset
df = pd.read_csv('/content/data.csv')

# Create binary target
df['pass'] = (df['Grades'] >= 50).astype(int)

# Features and Labels
X = df.drop(['Grades', 'pass'], axis=1)
y = df['pass']

# Normalize
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split Data
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# HyperModel for Keras Tuner
def build_model(hp):
    model = Sequential()
    model.add(Dense(units=hp.Int('units_input', min_value=16, max_value=128, step=16),
                    activation='relu',
                    input_shape=(X.shape[1],)))
    
    # Adding hidden layers based on hyperparameter tuning
    for i in range(hp.Int('num_layers', 1, 3)):
        model.add(Dense(units=hp.Int(f'units_{i}', min_value=16, max_value=128, step=16),
                        activation='relu'))
    
    model.add(Dense(1, activation='sigmoid'))  # Output layer
    
    model.compile(
        optimizer=keras.optimizers.Adam(
            hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),
        loss='binary_crossentropy',
        metrics=['accuracy'])
    
    return model

# Keras Tuner setup
tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,
    executions_per_trial=1,
    directory='my_dir',
    project_name='student_pass_predictor'
)

# Run Tuner
tuner.search(X_train, y_train, epochs=30, validation_split=0.2, verbose=0)

# Get best model
best_model = tuner.get_best_models(num_models=1)[0]

# Evaluate
test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=0)
print(f"\nFinal Test Accuracy after tuning: {test_acc * 100:.2f}%")

# Classification Report
y_pred = (best_model.predict(X_test) > 0.5).astype(int)
print("\n Classification Report:")
print(classification_report(y_test, y_pred))


OUTPUT:
Final Test Accuracy after tuning: 97.12%
9/9 ━━━━━━━━━━━━━━━━━━━━ 0s 13ms/step

Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.99      0.98       230
           1       0.95      0.88      0.91        48

    accuracy                           0.97       278
   macro avg       0.96      0.93      0.95       278
weighted avg       0.97      0.97      0.97       278
